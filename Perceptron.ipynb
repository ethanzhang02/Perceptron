{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Ethan Zhang ez2262"
      ],
      "metadata": {
        "id": "YEOj86ryZmA1"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tDOXLuk5Y5YI"
      },
      "outputs": [],
      "source": [
        "# Ethan Zhang ez2262\n",
        "import numpy as np\n",
        "from csv import reader\n",
        "# open file in read mode\n",
        "d = {}\n",
        "numrows = 0\n",
        "keyindex = 0\n",
        "with open('reviews_tr.csv', 'r') as read_obj:\n",
        "    # pass the file object to reader() to get the reader object\n",
        "    csv_reader = reader(read_obj)\n",
        "    next(csv_reader)\n",
        "    # Iterate over each row in the csv using reader object\n",
        "    for row in csv_reader:\n",
        "        # row variable is a list that represents a row in csv\n",
        "        numrows+=1\n",
        "        for word in (row[1]).split(' '):\n",
        "          if word not in d:\n",
        "            d[word] = keyindex\n",
        "            keyindex+=1\n",
        "unique = len(d)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ituwxbseKorn"
      },
      "outputs": [],
      "source": [
        "# Unigram for training\n",
        "from scipy.sparse import lil_matrix\n",
        "\n",
        "tf = lil_matrix((numrows, unique+1))\n",
        "with open('reviews_tr.csv', 'r') as read_obj:\n",
        "    csv_reader = reader(read_obj)\n",
        "    next(csv_reader)\n",
        "    curr_row = 0\n",
        "    for row in csv_reader:\n",
        "      for word in row[1].split(' '):\n",
        "        if word in d:\n",
        "          tf[curr_row, d[word]]+=1\n",
        "      tf[curr_row, unique] +=1\n",
        "      curr_row+=1\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Unigram for test\n",
        "tf_test = lil_matrix((numrows, unique+1))\n",
        "with open('reviews_te.csv', 'r') as read_obj:\n",
        "    # pass the file object to reader() to get the reader object\n",
        "    csv_reader = reader(read_obj)\n",
        "    next(csv_reader)\n",
        "    # Iterate over each row in the csv using reader object\n",
        "    curr_row = 0\n",
        "    for row in csv_reader:\n",
        "      for word in row[1].split(' '):\n",
        "        if word in d:\n",
        "          tf_test[curr_row, d[word]]+=1\n",
        "      tf_test[curr_row, unique] +=1\n",
        "      curr_row+=1"
      ],
      "metadata": {
        "id": "SdJK0nPNM5v6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xkfNor1aBXaX"
      },
      "outputs": [],
      "source": [
        "# tf-idf for training\n",
        "from scipy.sparse import csc_matrix\n",
        "\n",
        "idf = []\n",
        "tf_idf = tf.copy()\n",
        "tmp = tf.tocsc()\n",
        "for i in range(unique):\n",
        "  idf.append((tmp.getcol(i)).count_nonzero())\n",
        "\n",
        "for i in range(numrows):\n",
        "  for j in range(unique):\n",
        "    tf_idf[i, j] *= np.log10(numrows/idf[j])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# tf-idf on test\n",
        "tf_idf_test = tf_test.copy()\n",
        "for i in range(numrows):\n",
        "  for j in range(unique):\n",
        "    tf_idf_test[i, j] *= np.log10(numrows/idf[j])"
      ],
      "metadata": {
        "id": "kmoYZbU0M9js"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KnvJG9cLNIQp"
      },
      "outputs": [],
      "source": [
        "# bigram\n",
        "d_bigram = {}\n",
        "key_index_bigram = 0\n",
        "with open('reviews_tr.csv', 'r') as read_obj:\n",
        "    # pass the file object to reader() to get the reader object\n",
        "    csv_reader = reader(read_obj)\n",
        "    next(csv_reader)\n",
        "    # Iterate over each row in the csv using reader object\n",
        "    for row in csv_reader:\n",
        "        # row variable is a list that represents a row in csv\n",
        "        l = (row[1]).split(' ')\n",
        "        for i in range(1, len(l)):\n",
        "          if (l[i-1], l[i]) not in d_bigram:\n",
        "            d_bigram[(l[i-1], l[i])] = key_index_bigram\n",
        "            key_index_bigram+=1\n",
        "num_bigrams = len(d_bigram)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "4jOKG9dPblCP"
      },
      "outputs": [],
      "source": [
        "# bigram on training\n",
        "bigram = lil_matrix((numrows, num_bigrams+1))\n",
        "with open('reviews_tr.csv', 'r') as read_obj:\n",
        "    # pass the file object to reader() to get the reader object\n",
        "    csv_reader = reader(read_obj)\n",
        "    next(csv_reader)\n",
        "    # Iterate over each row in the csv using reader object\n",
        "    curr_row = 0\n",
        "    for row in csv_reader:\n",
        "      l = (row[1]).split(' ')\n",
        "      for i in range(1, len(l)):\n",
        "        if (l[i-1], l[i]) in d_bigram:\n",
        "          bigram[curr_row, d_bigram[(l[i-1], l[i])]]+=1\n",
        "      bigram[curr_row, num_bigrams] +=1\n",
        "      curr_row+=1"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# bigram on test\n",
        "bigram_test = lil_matrix((numrows, num_bigrams+1))\n",
        "with open('reviews_te.csv', 'r') as read_obj:\n",
        "    # pass the file object to reader() to get the reader object\n",
        "    csv_reader = reader(read_obj)\n",
        "    next(csv_reader)\n",
        "    # Iterate over each row in the csv using reader object\n",
        "    curr_row = 0\n",
        "    for row in csv_reader:\n",
        "      l = (row[1]).split(' ')\n",
        "      for i in range(1, len(l)):\n",
        "        if (l[i-1], l[i]) in d_bigram:\n",
        "          bigram_test[curr_row, d_bigram[(l[i-1], l[i])]]+=1\n",
        "      bigram_test[curr_row, num_bigrams] +=1\n",
        "      curr_row+=1"
      ],
      "metadata": {
        "id": "dFxOYWM6NTXy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Perceptron\n",
        "from sklearn.utils import shuffle\n",
        "\n",
        "def perceptron(matrix):\n",
        "\n",
        "  curr_weight = np.zeros(shape=(matrix.shape[1], 1))\n",
        "  with open('reviews_tr.csv', 'r') as read_obj:\n",
        "    csv_reader = reader(read_obj)\n",
        "    next(csv_reader)\n",
        "    curr_row = 0\n",
        "    for row in csv_reader:\n",
        "      dot_product = (matrix[curr_row].dot(curr_weight))[0][0]\n",
        "      if (int(row[0])==0 and dot_product>=0):\n",
        "        tmp = curr_weight-(matrix[curr_row].reshape(matrix.shape[1], 1))\n",
        "        curr_weight = np.squeeze(np.asarray(tmp)).reshape(matrix.shape[1], 1)\n",
        "      elif (int(row[0])==1 and dot_product<0):\n",
        "        tmp = curr_weight+(matrix[curr_row].reshape(matrix.shape[1], 1))\n",
        "        curr_weight = np.squeeze(np.asarray(tmp)).reshape(matrix.shape[1], 1)\n",
        "      curr_row+=1\n",
        "  \n",
        "  # pass 2\n",
        "  total_weight = curr_weight\n",
        "  matrix = shuffle(matrix)\n",
        "  with open('reviews_tr.csv', 'r') as read_obj:\n",
        "    csv_reader = reader(read_obj)\n",
        "    next(csv_reader)\n",
        "    curr_row = 0\n",
        "    for row in csv_reader:\n",
        "      dot_product = (matrix[curr_row].dot(curr_weight))[0][0]\n",
        "      if (int(row[0])==0 and dot_product>=0):\n",
        "        tmp = curr_weight-(matrix[curr_row].reshape(matrix.shape[1], 1))\n",
        "        curr_weight = np.squeeze(np.asarray(tmp)).reshape(matrix.shape[1], 1)\n",
        "      elif (int(row[0])==1 and dot_product<0):\n",
        "        tmp = curr_weight+(matrix[curr_row].reshape(matrix.shape[1], 1))\n",
        "        curr_weight = np.squeeze(np.asarray(tmp)).reshape(matrix.shape[1], 1)\n",
        "      curr_row+=1\n",
        "  \n",
        "      \n",
        "  return 1/(matrix.shape[0]+1) * total_weight\n",
        "  "
      ],
      "metadata": {
        "id": "avTkEQ0H2B5Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "unigram_perceptron = perceptron(tf)"
      ],
      "metadata": {
        "id": "sDZjqB_fNif0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a = np.squeeze(np.asarray(unigram_perceptron))\n",
        "indices = np.argsort(a)\n",
        "print(a)\n",
        "print(indices[::-1][:10])\n",
        "top_indices = list(indices[::-1][:10])\n",
        "worst_indices = list(indices[:10])\n",
        "print(max(a))\n",
        "print(min(a))\n"
      ],
      "metadata": {
        "id": "MGr31pbAa0cL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1d348d9f-583e-4900-8a1f-1e5de36e1004"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[-1.9999980e-06  3.9999960e-06 -8.9999910e-06 ...  0.0000000e+00\n",
            "  0.0000000e+00  1.3999986e-05]\n",
            "[546   5 135 152 981 347  91 571 185 539]\n",
            "4.6999953000047e-05\n",
            "-5.8999941000059004e-05\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "top_words = [0]*10\n",
        "for key in d:\n",
        "  if d[key] in top_indices:\n",
        "    top_words[top_indices.index(d[key])] = key\n",
        "print(top_words)\n",
        "worst_words = [0]*10\n",
        "for key in d:\n",
        "  if d[key] in worst_indices:\n",
        "    worst_words[worst_indices.index(d[key])] = key\n",
        "print(worst_words)"
      ],
      "metadata": {
        "id": "ywEAG1vAb3C-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1a0e0f98-c6ce-40cc-97c1-5f077acafc60"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['best', 'great', 'love', 'delicious', 'vegas', 'amazing', 'all', 'well', 'friendly', 'your']\n",
            "['not', 'if', 'no', 'only', 'average', 't', 'bad', 'she', 'came', 'manager']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def accuracy(weights, test_matrix):\n",
        "  correct = 0\n",
        "  with open('reviews_te.csv', 'r') as read_obj:\n",
        "    csv_reader = reader(read_obj)\n",
        "    next(csv_reader)\n",
        "    curr_row = 0\n",
        "    for row in csv_reader:\n",
        "      dot_product = (test_matrix[curr_row].dot(weights))[0][0]\n",
        "      if (dot_product<0 and int(row[0])==0) or (dot_product>=0 and int(row[0])==1):\n",
        "        correct+=1\n",
        "      curr_row+=1\n",
        "  return correct/curr_row\n"
      ],
      "metadata": {
        "id": "G6auBLK0J0j0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a = accuracy(unigram_perceptron, tf_test)\n",
        "print(a)"
      ],
      "metadata": {
        "id": "mePfkfgvLikq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f7e2da3e-4c5a-4cbb-a66b-c8b8d4deec80"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.7945751932075896\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "unigram_perceptron = perceptron(tf)\n",
        "tf_idf_perceptron = perceptron(tf_idf_test)\n",
        "bigram_perceptron = perceptron(bigram_test)"
      ],
      "metadata": {
        "id": "Y3gT6airVhQ6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "unigram_accuracy = accuracy(unigram_perceptron, tf_test)\n",
        "tf_idf_accuracy = accuracy(tf_idf_perceptron, tf_test)\n",
        "bigram_accuracy = accuracy(bigram_perceptron, tf_test)"
      ],
      "metadata": {
        "id": "o-nJy36OVbGR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "x1 = [500000,650000,800000,1000000]\n",
        "x2 = [500000,650000,800000,1000000]\n",
        "x3 = [500000,650000,800000,1000000]\n",
        "y1 = [0.855, 0.845, 0.872, 0.88]\n",
        "y2 = [0.84, 0.855, 0.86, 0.87]\n",
        "y3 = [0.86, 0.868, 0.894, 0.9045]\n",
        "\n",
        "plt.plot(x1,y1, label=\"Unigram\")\n",
        "plt.plot(x2,y2, label=\"tf-idf\")\n",
        "plt.plot(x3,y3, label=\"Bigram\")\n",
        "plt.legend()\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.xlabel(\"Training Size\")\n",
        "plt.title(\"Unigram vs tf-idf vs Bigram on Training Size w/Original Test Size\")\n",
        "plt.savefig(\"Train.png\")"
      ],
      "metadata": {
        "id": "LGfn-2jUZweK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "x1 = [800000,1000000, 1200000]\n",
        "x2 = [800000,1000000, 1200000]\n",
        "x3 = [800000,1000000, 1200000]\n",
        "y1 = [0.863, 0.88, 0.89]\n",
        "y2 = [0.862, 0.87, 0.875]\n",
        "y3 = [0.890, 0.9045, 0.90]\n",
        "\n",
        "plt.plot(x1,y1, label=\"Unigram\")\n",
        "plt.plot(x2,y2, label=\"tf-idf\")\n",
        "plt.plot(x3,y3, label=\"Bigram\")\n",
        "plt.legend()\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.xlabel(\"Training Size\")\n",
        "plt.title(\"Unigram vs tf-idf vs Bigram on Different Train/Test Splits\")\n",
        "plt.savefig(\"TrainTest.png\")"
      ],
      "metadata": {
        "id": "z1fE6J9KZ5jc"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}